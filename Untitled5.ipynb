{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/yCGgSZ7R6GfvZgGa/yO6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"09AY6T91co4W","executionInfo":{"status":"error","timestamp":1712575419021,"user_tz":-330,"elapsed":10656,"user":{"displayName":"Bharat Patidar","userId":"04847013604530439119"}},"outputId":"9df371ee-3454-426c-d64e-be3d1cafbabd"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/data.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-22054f27b482>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Read data from CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Extract texts and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data.csv'"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.optimizers import Adam\n","\n","# Define classes for custom training and testing epochs\n","class TrainEpoch:\n","    def _init_(self, model, X_train, y_train, batch_size):\n","        self.model = model\n","        self.X_train = X_train\n","        self.y_train = y_train\n","        self.batch_size = batch_size\n","        self.num_batches = X_train.shape[0] // self.batch_size\n","\n","    def run(self):\n","        for batch_idx in range(self.num_batches):\n","            start_idx = batch_idx * self.batch_size\n","            end_idx = min(start_idx + self.batch_size, self.X_train.shape[0])\n","            X_batch = self.X_train[start_idx:end_idx]\n","            y_batch = self.y_train[start_idx:end_idx]\n","            loss, _ = self.model.train_on_batch(X_batch, y_batch)\n","            print(f\"Batch {batch_idx + 1}/{self.num_batches}, Loss: {loss}\")\n","\n","class TestEpoch:\n","    def _init_(self, model, X_test, y_test):\n","        self.model = model\n","        self.X_test = X_test\n","        self.y_test = y_test\n","\n","    def run(self):\n","        X_test_dense = self.X_test.toarray()  # Convert to dense array for immediate solution\n","        loss, accuracy = self.model.evaluate(X_test_dense, self.y_test)\n","        print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n","\n","# Read data from CSV file\n","data = pd.read_csv('/content/data.csv')\n","\n","# Extract texts and labels\n","texts = data['text'].tolist()\n","labels = data['label'].tolist()\n","\n","# Define categories\n","categories = ['education', 'religious', 'legal']\n","\n","# Define label mapping dynamically\n","label_mapping = {category: i for i, category in enumerate(categories)}\n","y = np.array([label_mapping.get(label, -1) for label in labels])\n","\n","# Function to preprocess text\n","def preprocess_text(text, label_names):\n","    words = text.split()\n","    filtered_words = [word for word in words if word.lower() not in label_names]\n","    return \" \".join(filtered_words)\n","\n","# Preprocess the 'texts' array before feature extraction\n","processed_texts = [preprocess_text(text, categories) for text in texts]\n","\n","# Feature extraction (using the preprocessed texts)\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(processed_texts)\n","\n","# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n","\n","# Define neural network architecture\n","model = Sequential()\n","model.add(Dense(256, input_shape=(X_train.shape[1],), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(len(categories), activation='softmax'))  # Output layer with softmax activation for multi-class classification\n","\n","# Compile the model\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n","\n","# Train the model\n","batch_size = 32\n","num_epochs = 20\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n","    train_epoch = TrainEpoch(model, X_train, y_train, batch_size)\n","    train_epoch.run()\n","    test_epoch = TestEpoch(model, X_test, y_test)\n","    test_epoch.run()\n","\n","# Prediction code\n","def predict_labels(model, vectorizer, sentences, label_mapping):\n","    # Preprocess the sentences\n","    processed_sentences = [preprocess_text(sentence, categories)\n","                           for sentence in sentences]\n","    X = vectorizer.transform(processed_sentences)\n","\n","    # Handle sparse features (choose one of the methods):\n","    if hasattr(model.layers[0], 'get_weights') and not model.layers[0].get_weights()[0].shape[0]:\n","        # Model expects sparse features\n","        X_sparse = tf.sparse.reorder(tf.sparse.from_dense(X))\n","        predictions = model.predict(X_sparse)\n","    else:\n","        # Model expects dense features\n","        predictions = model.predict(X.toarray())\n","\n","    # Get class indices with highest probability\n","    predicted_class_indices = np.argmax(predictions, axis=1)\n","\n","    # Map indices back to original labels\n","    predicted_labels = [label_mapping[index] for index in predicted_class_indices]\n","\n","    return predicted_labels\n","\n","# Example usage\n","sentences = [\n","    # Educational\n","    \"The periodic table organizes elements according to their atomic structure.\",\n","    \"The Renaissance was a period of artistic and intellectual flourishing in Europe.\",\n","    \"Climate change is a complex issue with global environmental consequences.\",\n","    \"Understanding basic programming concepts is valuable in many fields.\",\n","    \"The human brain is a remarkably complex organ responsible for thought and behavior.\",\n","    \"Scientific research has led to many groundbreaking medical advancements.\",\n","    \"Studying philosophy helps develop critical thinking and analytical skills.\",\n","    \"Knowledge of history provides context for understanding current events.\",\n","    \"Learning about different cultures promotes global awareness and understanding.\",\n","    \"The scientific method relies on experimentation and observation.\",\n","\n","    # Religious\n","    \"The Bible is a sacred text for Christians.\",\n","    \"Many religions emphasize the importance of compassion and forgiveness.\",\n","    \"Religious beliefs often provide a sense of community and belonging.\",\n","    \"Meditation is a practice found in various spiritual traditions.\",\n","    \"Pilgrimages are journeys to places of religious significance.\",\n","    \"The Quran is the central religious text of Islam.\",\n","    \"Faith can be a source of strength and guidance in difficult times.\",\n","    \"Religious holidays and festivals are important in many cultures.\",\n","    \"Different religions have varying beliefs about the afterlife.\",\n","    \"The concept of karma is found in Hinduism and Buddhism.\",\n","\n","    # Legal\n","    \"The Constitution is the supreme law of the United States.\",\n","    \"Laws are created by legislatures and interpreted by courts.\",\n","    \"Contracts are legally binding agreements between parties.\",\n","    \"A jury determines guilt or innocence in a criminal trial.\",\n","    \"Civil lawsuits resolve disputes between individuals or organizations.\",\n","    \"Traffic laws are designed to promote road safety.\",\n","    \"Laws protect intellectual property, such as patents and copyrights.\",\n","    \"It is important to understand your legal rights as a citizen.\",\n","    \"Lawyers provide legal advice and representation in court.\",\n","    \"Tax laws determine how much individuals and businesses owe in taxes.\"\n","]\n","\n","reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n","predicted_labels = predict_labels(model, vectorizer, sentences, reverse_label_mapping)\n","\n","for sentence, label in zip(sentences, predicted_labels):\n","    print(f\"'{sentence}' - Predicted Label: {label}\")"]}]}